{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_text_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlNgmN5CPmIH",
        "outputId": "8aaf3325-daf9-4cd9-c8e5-ad0fe22ec050"
      },
      "source": [
        "! pip install tensorflow_history_plot"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_history_plot in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow_history_plot) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from tensorflow_history_plot) (3.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from tensorflow_history_plot) (2.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow_history_plot) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow_history_plot) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow_history_plot) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow_history_plot) (2.8.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow_history_plot) (0.3.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow_history_plot) (1.12)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow_history_plot) (1.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow_history_plot) (0.2.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow_history_plot) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow_history_plot) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow_history_plot) (2.4.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow_history_plot) (0.10.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow_history_plot) (3.7.4.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow_history_plot) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow_history_plot) (1.15.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow_history_plot) (1.32.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow_history_plot) (3.3.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow_history_plot) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow_history_plot) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow_history_plot) (3.12.4)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow_history_plot) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->tensorflow_history_plot) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->tensorflow_history_plot) (0.4.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->tensorflow_history_plot) (1.27.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->tensorflow_history_plot) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->tensorflow_history_plot) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->tensorflow_history_plot) (54.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->tensorflow_history_plot) (1.8.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow->tensorflow_history_plot) (3.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->tensorflow_history_plot) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->tensorflow_history_plot) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->tensorflow_history_plot) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->tensorflow_history_plot) (4.7.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->tensorflow_history_plot) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->tensorflow_history_plot) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->tensorflow_history_plot) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->tensorflow_history_plot) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow->tensorflow_history_plot) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->tensorflow_history_plot) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->tensorflow_history_plot) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-sqEYFVP3mp"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLA8JQCSqivM"
      },
      "source": [
        "# Dataset\n",
        "数据集为莎士比亚数据集，包含了一些莎士比亚文章"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKSeJfFPquXR"
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biQDQTiDq5oU",
        "outputId": "2da00428-694b-46a3-d0d6-d07b20d237bb"
      },
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XzaMuTwsgcQ",
        "outputId": "bdeb0307-c545-4e8b-db1f-fb7c26a5e0b5"
      },
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPtlPi5uspW0",
        "outputId": "394cef7c-3d58-4dda-b498-116d65aeafbb"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78nhvLqjtAzm"
      },
      "source": [
        "# Process Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrwSU2jBwCVz"
      },
      "source": [
        "我们需要构建一个字母到数字id的映射，首先需要把所有单词拆分成字母列表。可以使用`tf.strings.unicode_split`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ALNAEimtCdH",
        "outputId": "460b31f7-d890-4054-91d5-ee63d6235c6d"
      },
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63L8shg02Ef-"
      },
      "source": [
        "可以使用vocab来构建这个字典preprocessing.StringLookup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkx1gRLcv9g2"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(vocabulary=list(vocab))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoHZnB5i2YMM"
      },
      "source": [
        "用上面的chars来试试"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Khc4DTv2R8F",
        "outputId": "028dc221-4251-4ad3-8199-0f8e1025d5c8"
      },
      "source": [
        "ids=ids_from_chars(chars)\n",
        "ids"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[41, 42, 43, 44, 45, 46, 47], [64, 65, 66]]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WITVlgvr3Li4"
      },
      "source": [
        "最终我们要将网络的输出转为文字，因此还需要一个id到字母的映射"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1OaWcbG2S9e"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwoP4gzv3azK",
        "outputId": "1d66ca01-85a9-4ad0-fcd0-e68e64f12bac"
      },
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcZZbO1X8BUk"
      },
      "source": [
        "建个函数把字母拼回去"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9Tc4-RH3k_w"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if5qRZJC8ME1",
        "outputId": "7d8513ee-609d-4703-c360-d017855c846d"
      },
      "source": [
        "text_from_ids(ids)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'abcdefg', b'xyz'], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9Li8WaIGv0r"
      },
      "source": [
        "# Build Dataset\n",
        "我们现在有的东西只有文章的txt。需要自己构建数据集。\n",
        "\n",
        "最终期望的效果是，给模型一个至多个起始字符，模型要给出后续出现的字符，字符组成词，词再组成句子。\n",
        "\n",
        "因为我们是字符级别的预测，所以模型的输入应当是一个字符序列，模型的输出应该也是序列，包含每次输入字符之后应该出现的字符。举个例子，模型的输入是[H,E,L,L]，那么输出应该是[E,L,L,O]。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8O_zJI78RsR",
        "outputId": "e1dd0541-45cf-4e01-8567-ecf7446c8cfb"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([20, 49, 58, ..., 47, 10,  2])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPzbo7t6WaNd",
        "outputId": "711c5499-a011-47c3-e898-24b15a7db058"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmHmhnZxWzzw",
        "outputId": "d64afed3-e2e5-40ed-a8a6-f7207d35dbf2"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "examples_per_epoch"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11043"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVwUneGuXIr0",
        "outputId": "05640bd2-0091-438c-ba0b-037af5a0dd23"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOcXaUa2XiFT"
      },
      "source": [
        "构建（input, label）对"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EFPFmPKXYLm"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPf9t-LuXqqJ",
        "outputId": "9e17078c-f26c-4ff4-8319-3fa0b879386a"
      },
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WQ2L2cMXsl5"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFxynWmKX3mj",
        "outputId": "64d6e29d-e2aa-430d-c57a-afe453cab370"
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrBE-kdlX6K2"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "train_ds=dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxQYe8ydZazt",
        "outputId": "de5ec5bc-ab26-4399-afd6-c1137f665a10"
      },
      "source": [
        "train_ds"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbPAgXTVgaxB"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJHvN8N4an6L"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV3JXm-BDdhZ"
      },
      "source": [
        "因为网络内部有一些逻辑判断，所以这次我们没用Sequantial的方式快速构建网络，而是继承tf.keras.Model搭建网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlvVZ-JGA7ee"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else: \n",
        "      return x"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba9XdFh-E-OY"
      },
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1PEO203H7i4"
      },
      "source": [
        "试一下模型前馈。因为没训练，现在的输出是很混乱的。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSOfQo0AE-06",
        "outputId": "4192e298-ce6d-42e3-853b-7754e03795d8"
      },
      "source": [
        "for input_example_batch, target_example_batch in train_ds.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 67) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2Qe8aDxGDVJ",
        "outputId": "93da60f1-31b4-4b6b-f364-504b24d890db"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  17152     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    multiple                  3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  68675     \n",
            "=================================================================\n",
            "Total params: 4,024,131\n",
            "Trainable params: 4,024,131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag-SqdcuGdSH",
        "outputId": "50c35185-7faf-437e-8f0d-01747e731a80"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b' to thy cold\\nbed, and warm thee.\\n\\nHostess:\\nI know my remedy; I must go fetch the\\nthird--borough.\\n\\nSL'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'XbW CczqomFLYY?auB!b?VdfEqwFgY\\ngAQJQqawC-ZmRBZxf A3zwN[UNK]DtEIRyRXmxFkBMg?nTAphO.BHQxmstE.\\nokurQGxslc'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_LSOyHTJ-Ee"
      },
      "source": [
        "# Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikZBdze4G_9H"
      },
      "source": [
        "model.compile(optimizer='adam', loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTEdVOSCKLfj"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1j3QeAcKNwv"
      },
      "source": [
        "配一个checkpoint的callback，用来在训练过程中保存每一个epoch得到的模型。这样因为意外停止训练后还可以重新load模型继续训练。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIYP5RbJKDjU"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Rc-qfWyKg7R",
        "outputId": "b5c816e3-9cc8-4777-b210-7729973f1df4"
      },
      "source": [
        "EPOCHS = 20\n",
        "history = model.fit(train_ds, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 11s 51ms/step - loss: 3.3362\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 10s 51ms/step - loss: 2.1015\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 10s 52ms/step - loss: 1.7782\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 10s 53ms/step - loss: 1.5855\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 10s 53ms/step - loss: 1.4677\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 10s 54ms/step - loss: 1.3944\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 10s 54ms/step - loss: 1.3369\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 10s 55ms/step - loss: 1.2891\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 10s 55ms/step - loss: 1.2452\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.2035\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.1616\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.1189\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.0760\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.0290\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 0.9783\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 10s 56ms/step - loss: 0.9263\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.8743\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.8225\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.7680\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.7167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VoW1IDzOQVh"
      },
      "source": [
        "# Generate Text\n",
        "![](https://www.tensorflow.org/tutorials/text/images/text_generation_sampling.png?authuser=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv-QrPQfKnsI"
      },
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature=temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['','[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices = skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())]) \n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits] \n",
        "    predicted_logits, states =  self.model(inputs=input_ids, states=states, \n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzXGhakLPYvq"
      },
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nesTuEVPcr4",
        "outputId": "b8b34fa2-963a-4473-c75e-a428d2fb8a63"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "\n",
        "print(f\"\\nRun time: {end - start}\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "The best and the controversy bless,\n",
            "A rarmorn's washigh on the end o'er!\n",
            "\n",
            "Third Gentleman:\n",
            "And those are yet shall shortly sent thee to your house.\n",
            "\n",
            "GRUMIO:\n",
            "They super that, have I had been warrant,\n",
            "Tranio is but a did.\n",
            "\n",
            "LADY ANNE:\n",
            "And I am content;\n",
            "Come, my Saino's basening. I'll go so?\n",
            "\n",
            "POLIXENES:\n",
            "O sweet lusu!\n",
            "\n",
            "SICINIUS:\n",
            "Hie the poxt that we cannot distress\n",
            "Send for all the moon own kind, for this\n",
            "Is three are great; what do at the foe?\n",
            "Ah, what's unrely hence, where he should have wanting.\n",
            "\n",
            "MERCUTIO:\n",
            "And by my friend, and thou abidem,\n",
            "That, nor my heart they stop, that tetious wife,\n",
            "Whom I at him shall-folling eyes shall be\n",
            "the world at home:\n",
            "Choss here my father, I'll be so happily!\n",
            "That I, unto profess the strange princes;\n",
            "Until that hated through cares he is.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Within this hour before his hopes in tage,\n",
            "That he shuts upon thee, that did slay me\n",
            "To make upon mine own report for beauty sun.\n",
            "My father death, condition, sir, we would\n",
            "one sigh o'erwhelm'd affliction  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.6017134189605713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZRekrm-PrX4"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}